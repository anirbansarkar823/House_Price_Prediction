# -*- coding: utf-8 -*-
"""House Price Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OCh8Jm4t0IrsawEALfALDVgLfjMDfcpd
"""

from google.colab import drive
drive.mount('/content/drive')

path = "/content/drive/MyDrive/Colab Notebooks/housing.csv"
df_data = pd.read_csv(path, header=None )
# Dataset is now stored in a Pandas Dataframe
df_data.head()

pd.read_csv?

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn.datasets
from sklearn.model_selection import train_test_split
from xgboost import XGBRegressor
from sklearn import metrics ## for regression problem

# importing boston house price dataset from sklearn datasets
house_price_dataset = sklearn.datasets.load_boston()

# house_price_dataset is not a df
type(house_price_dataset)

print(house_price_dataset)

print(house_price_dataset.data)

house_price_dataset.feature_names

pd.DataFrame?

# loading the house_price_dataset into dataframe without columns
house_price_df = pd.DataFrame(data=house_price_dataset.data)
house_price_df.head() #don't use head; use head()
# print(type(house_price_df))

# loading the house_price_dataset into dataframe with columns
house_price_df = pd.DataFrame(house_price_dataset.data, columns = house_price_dataset.feature_names)
house_price_df.head()

# adding the target column to the dataframe
# we will add one column
house_price_df['price'] = house_price_dataset.target
house_price_df.head()

# checking the number of rows and columns in the dataframe
house_price_df.shape

# checking for missing values: per column
house_price_df.isnull().sum()

# stats for each column
house_price_df.describe()

"""#### corelation among variable: positive or negative"""

correlation = house_price_df.corr()
correlation

# constructing heatmap to understand the correlation
plt.figure(figsize=(10,10))
sns.heatmap(correlation, annot=True, cbar=True, square=True, fmt='.2f', annot_kws={'size':8}, cmap='Blues')
# annot = True: means we need the numeric values to be present over squares
# cbar = True: the side bar
# fmt: how many float values we want after decimal point
#

# RAD is highly correlated with TAX

sns.heatmap?

# spliting columns into X, Y i.e., dependant and independant variables
X = house_price_df.drop('price', axis=1, inplace=False)
y = house_price_df['price']

print(X)
print(y)

# splitting the data into training and test data
x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=2)

print(X.shape, x_train.shape, x_test.shape)

"""#### Model Training"""

# we will use the SGBoost Regressor
model = XGBRegressor()

# training the model with X-train
model.fit(x_train, y_train)

"""### Evaluation"""

# evaluation on training set first
predicted_train_values = model.predict(x_train)

# metrics 
score_train = metrics.r2_score(y_train, predicted_train_values)
print(f"r2_score for training set: {score_train}")

score_train_mae = metrics.mean_absolute_error(y_train, predicted_train_values)
print(f"mae for training set: {score_train_mae}")

# evaluation on test set 
predicted_test_values = model.predict(x_test)

# metrics 
score_test_r2 = metrics.r2_score(y_test, predicted_test_values)
print(f"r2_score for test set: {score_test_r2}")

score_test_mae = metrics.mean_absolute_error(y_test, predicted_test_values)
print(f"mae for test set: {score_test_mae}")

"""### Visualising the Result"""

# plotting the trianing labels and predicted labels on training
plt.scatter(y_train, predicted_train_values)
plt.xlabel("Actual prices")
plt.ylabel("predicted prices")
plt.title("Training data: actual vs predicted prices")
plt.show()

# plotting the trianing labels and predicted labels on training
plt.scatter(y_test, predicted_test_values)
plt.xlabel("Actual prices")
plt.ylabel("predicted prices")
plt.title("Test data: actual vs predicted prices")
plt.show()